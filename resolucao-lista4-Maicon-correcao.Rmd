---
title: "Resolução da lista 4 de ADAR"
author: "Maicon Fonseca Andrades"
date: "01/02/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<!-- 
Lista 4 original foi dividida em duas:
uma com exercícios tidyr e outra com dplyr
-->


## Pré-requisitos

**Pacotes necessários**

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(easypackages)

pacotes <- c(
  "openair",
  "lubridate",
  "scales",
  "rio",
  "readr",
  "dplyr",
  #"hablar", #?
  "stringr"
)
library(stringr)
libraries(pacotes)
```


**Dados**

```{r, eval = FALSE}
arq_temp <- tempfile(fileext = ".RData")
#arq_temp <- "dados-lista-exerc4-cap9.RData"
download.file(
  "https://github.com/lhmet/adar-ufsm/blob/master/data/dados-lista-exerc4-cap9.RData?raw=true",
  destfile = arq_temp,
  mode = "wb"
)
# nome dos dados carregados para os exercícios
print(load(arq_temp))
```


> Para reprodutibilidade

```{r}
arq_temp <- tempfile(fileext = ".RData")
if (Sys.info()[["user"]] == "hidrometeorologista") {
  arq_temp <- "dados-lista-exerc4-cap9.RData"
}

if (!file.exists(arq_temp)) {
  download.file(
    "https://github.com/lhmet/adar-ufsm/blob/master/data/dados-lista-exerc4-cap9.RData?raw=true",
    destfile = arq_temp,
    mode = "wb"
  )
}
# nome dos dados carregados para os exercícios
print(load(arq_temp))
```


## Exercícios

1. Converta os dados de anomalias padronizadas do índice de oscilação sul armazenados no *quadro de dados* `soi` (mostrado abaixo) para o formato \"arrumado\" e em ordem cronológica. Os nomes das variáveis na tabela de dados arrumado deve estar sempre em letras minúsculas (conheça a função `tolower()`).

A estrutura esperada dos dados processados é mostrada abaixo: 

```
Rows: 36
Columns: 3
$ year <int> 1951, 1951, 1951, 1951, 1951, 1951, 19...
$ mes  <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,...
$ soi  <dbl> 1.5, 0.9, -0.1, -0.3, -0.7, 0.2, -1.0,...
```

```{r}

# verificando a estrutura dos dados
str(soi)

# coersão do data frame para tibble
soi_tbl <- as_tibble(soi)
#! Error in as_tibble(soi) : could not find function "as_tibble"
(soi_tbl)

# reestruturando os dados em uma nova tabela
soi_tbl_long <- pivot_longer(
  data = soi_tbl,
  cols = c(2:13),
  names_to = "MES",
  values_to = "SOI"
)
# alterando os nomes das variaveis para letras minusculas
names(soi_tbl_long) <- tolower(names(soi_tbl_long))

# convertendo a coluna mes para inteiro
soi_tbl_long <- transform(soi_tbl_long, mes = as.integer(mes))

# organizando os dados em ordem cronológica
soi_tbl_long <- soi_tbl_long[order(soi_tbl_long$year),]

# verificando a estrutura do quadro de dados
glimpse(soi_tbl_long)
```

> Você usou a `transform()` mas neste capítulo foi ensinado a `mutate()` que tem várias vantagens (ver livro). Procure usá-la.


```{r jdt-correcao1, echo = FALSE, comment="JDT>"}
# penalizacoes
p1 <- 0
# nota questão 1
(nq1 <- 1 - p1)
```

- - -


2. Faça a conversão dos dados de precipitação diária, armazenados em um **`tibble**`, para o \"formato arrumado\" e transforme as datas para o tipo de dados *date*.
A estrutura esperada do **`tibble`** resultante é mostrada abaixo:
```
Rows: 40
Columns: 4
$ x    <dbl> -60.625, -60.625, -60.625, -60.625, -60.625, -60.625, -6...
$ y    <dbl> 5.125, 5.125, 5.125, 5.125, 5.125, 5.125, 5.125, 5.125, ...
$ date <date> 2010-01-01, 2010-01-02, 2010-01-03, 2010-01-04, 2010-01...
$ prec <dbl> 0.0000000, 0.0000000, 0.0000000, 0.4484863, 2.3515625, 4...
```


```{r}

# verificando a estrutura dos dados
#! str(precd_ncdf)

# coersão do data frame para tibble
precd_tbl <- as_tibble(precd_ncdf)
#! head(precd_tbl, n = 5)

# reestruturando os dados em uma nova tabela
precd_tbl_long <- pivot_longer(
  data = precd_tbl,
  cols = c(3:10), # use nomes como referências às variáveis, 
                  # 'cols = -c(x, y)' 
                  # assim se mudar a ordem das variáveis isso não afetará o resultado.
                  # É uma boa prática de programação.
  names_to = "date",
  values_to = "prec"
) %>%
  #! USE O QUE FOI ENSINADO NO CAPÍTULO: mutate()
  mutate(date = as.Date(date, "X%Y.%m.%d"))
#head(precd_tbl_long, n = 5)

# removendo o character "X' da coluna date 
#! precd_tbl_long$date <- str_replace_all(precd_tbl_long$date, pattern = "[X]", "")

# outra forma de remover:
#precd_tbl_long$date <- gsub("X", "", precd_tbl_long$date)

# convertendo a coluna das datas para o formato date
#! precd_tbl_long$date <- format(as.Date(x = precd_tbl_long$date, "%Y.%m.%d"), format = "%Y-%m-%d")
#! precd_tbl_long$date <- as.Date(precd_tbl_long$date)

# verificando a estrutura do quadro de dados
glimpse(precd_tbl_long)
```
> A idéia dos exercícios no final do capítulo é usar o que foi aprendido naquele capítulo (`mutate` ao invés de `x$var <- algocom(x$var)`).

```{r jdt-correcao2, echo = FALSE, comment="JDT>"}
# penalizacoes
p2 <- 0.05
# nota questão 2
(nq2 <- 1 - p2)
```


- - -


3. Coloque os dados de poluição (**`tibble`** `poluentes`) no formato \"arrumado\".


```{r}

# verificando a estrutura dos dados
#!str(poluentes)

# coersão do data frame para tibble
poluentes_tbl <- as_tibble(poluentes)
(poluentes_tbl)

# arrumando os dados
poluentes_tbl_w <- pivot_wider(
  data = poluentes_tbl,
  names_from = poluente,
  values_from = duracao
)
glimpse(poluentes_tbl_w)

# convertendo as colunas para numérico
#poluentes_arrumado <- transform(
#  poluentes_tbl_w,
#  ozone = parse_number(ozone),
#  so2 = parse_number(so2),
#  no2 = parse_number(no2)
#)
# verificando o data frame arrumado
#glimpse(poluentes_arrumado)

```

> Procure a apresentar somente o código necessário para resolver o problema específico. Você pode ter outra cópia para si, com código poluído se desejar.


```{r jdt-correcao3, echo = FALSE, comment="JDT>"}
# penalizacoes
p3 <- 0.05
# nota questão 2
(nq3 <- 1 - p3)
```


- - -


4. a. Coloque os dados meteorológicos diários da estação meteorológica de Santa Maria no formato arrumado. 
```
#> # A tibble: 12 x 35
#>    id    element month  year    d1    d2    d3    d4    d5    d6    d7    d8    d9   d10
#>    <chr> <chr>   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>
#>  1 83936 tmax        1  2010  32.6  33.4  24.8  29.4  27    24.4  29.6  29.4  29.6  31.8
#>  2 83936 tmin        1  2010  17.9  21.4  21.6  23.4  23.2  21.8  18    19.4  21.8  22.4
#>  3 83936 tmax        2  2010  36.8  38.4  32.6  38.6  34    36.4  29.8  31    32.8  33.6
#>  4 83936 tmin        2  2010  25.4  25    29.6  26.2  25    25.8  25.4  22.2  19.8  17.6
#>  5 83936 tmax        3  2010  32    32.4  33.6  32.4  32    29.6  30.2  30    31    32.6
#>  6 83936 tmin        3  2010  18.6  19    20.2  21.6  19.8  18.4  17.3  21.6  20.4  22.2
#>  7 83936 tmax        4  2010  34.4  28.6  21    24.2  23.4  24    24.6  26    27.6  30.2
#>  8 83936 tmin        4  2010  17.5  21    20.6  17.6  15    10.8  11.7  11.3  12.7  11.6
#>  9 83936 tmax        5  2010  27    26.4  20.2  22.8  25.4  17.4  19.6  19.8  17.2  17.4
#> 10 83936 tmin        5  2010   7.2   7    13    16.2  14.1  11.5  14.4  11     9.9   9  
#> 11 83936 tmax        6  2010  19.2  23.8  17.2  18.6  21.2  20.2  17.8  15.4  16.2  19  
#> 12 83936 tmin        6  2010   4.1   8.8   9.1  15.2  11.4   6.1   6.3   7.3   5.6   3.5
#> # … with 21 more variables: d11 <dbl>, d12 <dbl>, d13 <dbl>, d14 <dbl>, d15 <dbl>,
#> #   d16 <dbl>, d17 <dbl>, d18 <dbl>, d19 <dbl>, d20 <dbl>, d21 <dbl>, d22 <dbl>,
#> #   d23 <dbl>, d24 <dbl>, d25 <dbl>, d26 <dbl>, d27 <dbl>, d28 <dbl>, d29 <dbl>,
#> #   d30 <dbl>, d31 <dbl>
```

```{r}
# verificando a estrutura dos dados
#! str(dados_sm)

# coersão para tibble
dados_sm_tbl <- as_tibble(dados_sm)

# reestruturando os dados em uma nova tabela
dados_sm_long <- pivot_longer(
  data = dados_sm_tbl,
  cols = c(5:35),  # use as funções auxiliares seletoras! starts_with('d')
  names_to = "day",
  values_to = "value"
)

# verificando os dados
#!glimpse(dados_sm_long)

# os dados ainda não estão arrumados, é preciso separar a coluna element
dados_sm_wider <- pivot_wider(
  data = dados_sm_long,
  names_from = element,
  values_from = value
)
# verificando o data frame arrumado
glimpse(dados_sm_wider)
```


   b. Deixe os dados ordenados cronologicamente e obtenha as variáveis com nomes e ordem conforme mostrado na estrutura de dados esperada.
```
Rows: 186
Columns: 6
$ id    <chr> "83936", "83936", "83936", "83936", "83936", "...
$ year  <dbl> 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010...
$ month <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1...
$ day   <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,...
$ tmax  <dbl> 32.6, 33.4, 24.8, 29.4, 27.0, 24.4, 29.6, 29.4...
$ tmin  <dbl> 17.9, 21.4, 21.6, 23.4, 23.2, 21.8, 18.0, 19.4...
```

```{r}
# removendo o caracter "d" da coluna "day" e convertendo para inteiro

#! pq não usa MUTATE e pipe?
dados_sm_wider$day <- str_replace(dados_sm_wider$day, pattern = "[d]", replacement = "") 

dados_sm_wider$day <- as.integer(dados_sm_wider$day)

# ordenando as colunas
dados_sm_wider <-
  dados_sm_wider %>%
  select(id, year, everything())

# organizando os dados em ordem cronológica
#! ordenou APENAS POR ANO!
dados_sm_wider <- dados_sm_wider[order(dados_sm_wider$year),]

# verificando o data frame
glimpse(dados_sm_wider)

```

> A idéia dos exercícios no final do capítulo é usar o que foi aprendido naquele capítulo (`mutate` ao invés de `x$var <- algocom(x$var)` e `arrange()` ao invés de `order`). Esperava-se mais uso do pipe também. 

```{r, eval = FALSE}
dados_sm_wider %>%
  mutate(
    .data = .,
    day = as.integer(str_replace_all(day, "d", ""))
  ) %>%
  select(id, year, month, day, everything()) %>%
  arrange(year, month, day) %>%
  glimpse()
```


   c. Acrescente uma nova variável `tmed` aos dados de temperatura diária arrumados, obtida da média diária da `tmax` e `tmin`.
   
```{r}
# Acrescentando uma nova variável tmed
dados_sm_m <- 
  dados_sm_wider %>%
  mutate(., tmed = (tmax + tmin)/2)

glimpse(dados_sm_m)
```


```{r jdt-correcao4, echo = FALSE, comment = "JDT>"}
p4 <- (0.05 * 1/3) + (0.1 * 1/3)  
(nq4 <- 1 - p4)
```

- - -


5. Com os dados obtidos na questão 4c: 
   a. renomeie as as colunas `year`, `month` e `day`para `ano`, `mes` e `dia`, respectivamente.
   b. junte as colunas `ano`, `mes` e `dia` em uma única coluna denominada `data` de forma que a classe dessa nova váriavel seja `date`.
   c. Filtre os dados obtidos em **(b)** de forma a descobrir as datas em que as observações de `tmax` ou `tmin` são faltantes. Mostre o **`tibble`** filtrado com as datas e explique o porquê de seus valores. *DICA: quantas observações são esperadas por ano?*. 
   
   
```{r}
# a.

dados_sm_nome <-
  dados_sm_m %>%
  rename(., 
       "ano" = year,
       "mes" = month,
       "dia" = day)

glimpse(dados_sm_nome)
```
   
   
```{r}
# b.
# unindo as colunas
dados_sm_uni <- unite(
  data = dados_sm_nome,
  col = data,
  ano, mes, dia,
  sep = "-"
)
# convertendo para o formato de data
dados_sm_uni$data <- as.Date(dados_sm_uni$data)
# verificando o data frame
glimpse(dados_sm_uni)

```
> A idéia dos exercícios no final do capítulo é usar o que foi aprendido naquele capítulo (`mutate` ao invés de `x$var <- algocom(x$var)`). Use verbos para nomes de funções, não para dados.


```{r}
# c.
dados_sm_filtro_na <-
  dados_sm_uni %>%
  filter(., is.na(tmax) | is.na(tmin))

glimpse(dados_sm_filtro_na)

```
> A PERGUNTA É CLARA: QUAIS AS DATAS? NÃO FOI RESPONDIDO.

```{r}
dados_sm_nome %>%
  filter(., is.na(tmax) | is.na(tmin)) %>%
  select(., ano, mes, dia)
```

```{r jdt-correcao5, echo = FALSE, comment = "JDT>"}
p5 <- 1/3
(nq5 <- 1 - p5)
```

- - -


6. A amostra de dados abaixo possui medidas a cada 6 horas de uma estação meteorológica de superfície. Reestruture os dados no formato \"arrumado\" e junte as informações de data e horário em uma única variável da classe *POSIXct* denominada `date`.
```
#>         date tmax.0 tmax.600 tmax.1200 tmax.1800 tmin.0 tmin.600 tmin.1200 tmin.1800
#> 2 01-01-2010   22.1     21.0      26.4      27.0     16     13.5      18.2      24.1
#> 3 02-01-2010   26.0     25.0      29.4      29.5     19     13.7      16.3      22.3
#> 4 03-01-2010   25.7     26.3      28.4      29.0     21     14.1      17.2      26.0
#> 5 04-01-2010   23.5     24.5      27.4      28.0     23     16.2      16.9      23.0
```
A estrutura esperada do *tibble* resultante é mostrada abaixo:
```
Rows: 16
Columns: 3
$ date <dttm> 2010-01-01 00:00:00, 2010-01-01 06:00:00, 2010-01-01 12:00:00, 2010-01-01 18:...
$ tmax <dbl> 22.1, 21.0, 26.4, 27.0, 26.0, 25.0, 29.4, 29.5, 25.7, 26.3, 28.4, 29.0, 23.5, ...
$ tmin <dbl> 16.0, 13.5, 18.2, 24.1, 19.0, 13.7, 16.3, 22.3, 21.0, 14.1, 17.2, 26.0, 23.0, ...
```


> Você não incluiu esta dúvida no e-mail. Tem que aproveitar as oportunidades.
Me ajude a te ajudar. Este comentário não tinha no Rmd enviado por e-mail.

```{r}
# Não consegui separar as colunas. Nada que tentei deu certo,a não ser formas bem grosseiras.  

# verificando a estrutura dos dados
str(dados_zorra)

# coersão do data frame para tibble
dados_zorra_tb <- as_tibble(dados_zorra)
(dados_zorra_tb) #! Só o nome da variável já imprimime na tela o parenteses aqui é redundante 

# reestruturando os dados em uma nova tabela
dados_zorra_tbl <- pivot_longer(
  data = dados_zorra_tb,
  #cols = c(2:9), #! que perigo. Se alterar a ordem das colunas tá ferrado.
  cols = -date, #! código seguro
  names_to = "temp.h",
  values_to = "value"
)
```

```{r}
# separando a coluna tempH
dados_zorra_s <- separate(
  data = dados_zorra_tbl,
  col = temp.h,
  sep = ".",
  into = c("tmax", "tmin", "hora"), convert = TRUE, remove = FALSE, #! confusao - separate vai separar baseado em um separador, qual? apresenda a usar `?separate`, ver exemplos e quais valores default dos argumentos 
  extra = "merge")

```

> Essa questão requer a aplicação de funções vistas ao longo do curso.

```{r}
# solução
dados_zorra %>%
  # variaáveis (nome.hora) em uma coluna, valores em outra
  pivot_longer(.,
               cols = -date,
               names_to = "variavel",
               values_to = "valor"
               ) %>%
  # variaveis em uma coluna, valores em outra
  separate(
    .,
    col = variavel,
    into = c("varname", "hora")
    ) %>% 
  mutate(.,
         hora = ifelse(
           nchar(hora) >= 3,
           as.numeric(hora)/100, # 1200 --> 12
           as.numeric(hora) # 0
           ),
         hora = paste0(hora, ":00:00"), # como não tem segundos e a POSIX requer esta info
         date = as.Date(date, "%d-%m-%Y")
         ) %>%
  unite(., col = date, date, hora, sep = " ") %>%
  mutate(., date = as.POSIXct(date)) %>%
  pivot_wider(
    names_from = varname, 
    values_from = valor
    )
```


>  Pare de usar valores definidos na mão! Quando falo isso me refiro à c(2:9). Isso pode causar muita dor de cabeça! Reveja esta [seção](https://lhmet.github.io/adar-ebook/manipula%C3%A7%C3%A3o-de-dados.html#sele%C3%A7%C3%A3o-de-vari%C3%A1veis) em que demostro os seletores.

```{r jdt-correcao6, echo = FALSE, comment = "JDT>"}
p6 <- 2/3
(nq6 <- 1 - p6)
```

- - -


7. Faça uma junção da tabela de dados de informações das estações de poluição (`estacoes`, dada abaixo) com os períodos de duração de poluição crítica (`poluentes`). A tabela resultante deve conter somente estações que tenham coordenadas espaciais e medidas de poluentes válidas.
Estrutura da tabela resultante:
```
Rows: 3
Columns: 5
$ id       <int> 1, 1, 2
$ lat      <dbl> 42.46757, 42.46757, 42.04915
$ lon      <dbl> -87.81005, -87.81005, -88.27303
$ poluente <chr> "ozone", "so2", "ozone"
$ duracao  <chr> "1h", "1h", "8h"
```

```{r}

str(estacoes)
str(poluentes)

# coersão dos data.frames para tibble
estacoes_tb <- as_tibble(estacoes)
(estacoes_tb)

poluentes_tb <- as_tibble(poluentes)
(poluentes_tb)


poluente_novo = poluentes %>%
  rename(., "id" = estacao) %>% 
  select(id, everything())
  
glimpse(poluente_novo)

estacoes_poluentes <- inner_join(
  x = estacoes_tb, 
  y = poluente_novo,
  by = "id"
)

glimpse(estacoes_poluentes)
```

> Solução idêntica à do Ignazio. Zero. Até o nome das variáveis são idênticos.
A forma de resolução poderia coincidir, mas os nomes das 3 variáveis criadas seria
muita coincidência.

```{r jdt-correcao7, echo = FALSE, comment = "JDT>"}
p7 <- 1
(nq7 <- 1 - p7)
```

- - -


8. Combine as 2 tabelas abaixo de forma que:
  a. A tabela resultante contenha todas as datas compreendidas pelas duas tabelas (e em ordem cronológica) e as observações de umidade do solo (`theta`) sejam preenchidas com `NA`. 
  b. a tabela resultante contenha exatamente as datas da tabela `data_comp` (em ordem cronológica) e as observações de umidade do solo (`theta`) sejam preenchidas com `NA`.
  
```{r}
str(datas_comp)
str(datas_obs)

# coersão dos data.frames para tibble
datas_comp_tb <- as_tibble(datas_comp)
(datas_comp_tb)

datas_obs_tb <- as_tibble(datas_obs)
(datas_obs_tb)
```


```{r}
# a)
datas_full <- full_join(
  x = datas_comp_tb, 
  y = datas_obs_tb,
  by = "date")

datas_full <- datas_full[order(as.Date(datas_full$date, format="%Y-%m/%d")),]

glimpse(datas_full)

```
  
  
```{r}
# b)

datas_left <- left_join(
  x = datas_comp_tb, 
  y = datas_obs_tb,
  by = "date")

datas_left <- datas_left[order(as.Date(datas_left$date, format="%Y-%m/%d")),]

glimpse(datas_left)

```

> Esperava-se o uso da `arrange()`, ensinada no capítulo, ao invés de `order()`.

```{r jdt-correcao8, echo = FALSE, comment = "JDT>"}
p8 <- 0.05
(nq8 <- 1 - p8)
```


---


9. Utilizando os dados horários de estações meteorológicas automáticas (EMA) do RS (`dados_rs_08_16`), determine a data inicial, final e o período de dados (em anos) de cada estação (identificada pela variável `site`).


```{r}
# estrutura dos dados
#str(dados_rs_08_16)

#! e os anos bissextos? não existem nos seus dados?
nh <- 8760 # quantidade de horas em um ano 
# agrupando em função de cada estação
dados_rs_new <- 
  dados_rs_08_16 %>%
  group_by(., site) %>%
  summarise(.,
            inicio = date[which.min(date)], #! min(date) #-cálculo
            final = date[which.max(date)], #! max(date)
            period = n()/nh,
            .groups = 'drop')

#head(dados_rs_new, n= 5)

dados_rs_dec <- 
  dados_rs_new %>%
  arrange(., desc(site))

glimpse(dados_rs_dec)

```


> Faltou apenas mais precisão no cálculo do período, ignorou anos bissextos.
Agrupe por ano seus dados.

```{r jdt-correcao9, echo = FALSE, comment = "JDT>"}
p9 <- 0.1
(nq9 <- 1 - p9)
```

---


10. Determine a porcentagem de dados válidos (ou seja, não faltantes) de cada variável para cada EMA. Aproxime os valores para números inteiros.


```{r}

dados_rs_novo <-
  dados_rs_08_16 %>%
  group_by(., site) %>%
  summarise(.,
             tair = as.integer((sum(!is.na(tair))/n())*100),
             rh = as.integer((sum(!is.na(rh))/n())*100),
             prec = as.integer((sum(!is.na(prec))/n())*100),
             rg = as.integer((sum(!is.na(rg))/n())*100),
             ws = as.integer((sum(!is.na(ws))/n())*100),
             .groups = 'drop')

glimpse(dados_rs_novo)

```

> "Há mais funções úteis disponíveis no pacote dplyr e você é encorajado a descubrí-las.". Seção 10.4.7 do livro. ?summarise.

```{r}
percentual_valido <- function(col)
  as.integer(sum(!is.na(col)) / n() * 100)

dados_rs_08_16 %>%
  group_by(site) %>%
  summarise_all(percentual_valido) %>%
  select(-date)
#ou mais atual
dados_rs_08_16 %>%
  group_by(site) %>%
  summarise(across(tair:ws, percentual_valido))
```



```{r jdt-correcao10, echo = FALSE, comment = "JDT>"}
p10 <- 0.05
(nq10 <- 1 - p10)
```

---


11. Com o resultado da questão anterior, adicione uma variável indicativa da porcentagem média de observações válidas de todas variáveis. Ordene esta tabela em ordem decrescente da disponibilidade média de observações.


```{r}

dados_rs_disp <-
  dados_rs_novo %>%
  group_by(., site) %>%
  mutate(.,
         disp_med = (tair+rh+prec+rg+ws)/5) %>%
  arrange(., desc(disp_med))
  
glimpse(dados_rs_disp)
  
  
```
```{r jdt-correcao11, echo = FALSE, comment = "JDT>"}
p11 <- 0
(nq11 <- 1 - p11)
```

> "Há mais funções úteis disponíveis no pacote dplyr e você é encorajado a descubrí-las.". Seção 10.4.7 do livro. ?summarise. Note a importância de ler help e seguir as dicas do livro.

```{r}
percentual_valido <- function(col)
  as.integer(sum(!is.na(col)) / n() * 100)

dados_rs_08_16 %>%
  group_by(site) %>%
  summarise_all(percentual_valido) %>%
  select(-date)
#ou mais atual
dados_rs_08_16 %>%
  group_by(site) %>%
  summarise(across(tair:ws, percentual_valido))
```


12. Para a EMA de Santa Maria (ver `info_emas_rs_08_16`) obtenha o ciclo diurno médio da temperatura do ar e a porcentagem de dados válidos usados para compor a `tair` média de cada hora. 


```{r}
# de onde saiu o "A803"? olhômetro? pense como programador!
# id_site <- info_emas_rs_08_16 %>%
#   filter(name == "SANTA MARIA") %>%
#   pull(site)

ema_sm <-
  dados_rs_08_16 %>%
  filter(str_detect(site, "A803")) %>%
  #filter(str_detect(site, id_site)) %>%
  select(., site, date, tair) %>%
  mutate(., hora = hour(date))

#glimpse(ema_sm)

ema_sm_new <-
  ema_sm %>%
  group_by(., hora) %>%
  summarise(.,
            tair_med = mean(tair, na.rm = TRUE),
            tair_disp = (sum(!is.na(tair))/n())*100,
             .groups = 'drop')
glimpse(ema_sm_new)

```
```{r jdt-correcao12, echo = FALSE, comment = "JDT>"}
p12 <- 0
(nq12 <- 1 - p12)
```

---


13. Com os dados de temperatura do ar (`tair`) filtrados para EMA de Santa Maria (a) selecione somente os dias observações válidas nas 24 horas (dias completos, ou seja, sem nenhuma falha nas 24 h). A partir destes dados (b) obtenha a frequência de ocorrência da temperatura mínima para cada horário do dia. (c) Apresente a tabela de resultados em ordem decrescente da frequência de ocorrência.


```{r}
# a.
ema_sm_tair <-
  dados_rs_08_16 %>%
  filter(str_detect(site, "A803")) %>%
  select(., site, date, tair) %>%
  mutate(., dia = floor_date(date, unit = "day")) 

# elaborando um novo data frame com o dia e a porcentagem de dados disponíveis
sm_tair <-
  ema_sm_tair %>%
  group_by(., dia) %>%
  summarise(.,
            tair_val = as.integer((sum(!is.na(tair))/24)*100),
            .groups = 'drop')

# seleciona os dias com 100 % dos dados
dias_completos <-
  sm_tair %>%
  filter(., tair_val==100) %>%
  select(., dia)
  
glimpse(dias_completos)

glimpse(tail(dias_completos))

```


```{r}

# b.
ema_sm_tair <- 
  ema_sm_tair  %>% 
  #! FALTOU LER COM ATENÇÃO 'A partir destes dados (b) obtenha a frequência de ocorrência ...'
  #! inner_join(mutate(dias_completos, dia = floor_date(dia, unit = "day"))) %>%
  mutate(., hora = hour(date)) 

freq_tmin <-
  ema_sm_tair  %>% 
  group_by(., dia) %>%
  summarise(.,
            h_tmin = hora[which.min(tair)],
            .groups = 'drop') %>%
  group_by(., h_tmin) %>%
  count(h_tmin) 

glimpse(freq_tmin)

```


```{r}
# c.
# ordem decrescente da frequência de ocorrência
freq_htmin_dec <- 
  freq_tmin %>%
  arrange(., desc(n))

glimpse(freq_htmin_dec)

```

> Faltou usar datas completas na (b), descomente código para ver a diferença.

```{r jdt-correcao13, echo = FALSE, comment = "JDT>"}
p13 <- 2/3
(nq13 <- 1 - p13)
```

---


14. Neste exercício aplicaremos um controle de qualidade básico de dados meteorológicos. Você irá verificar se nos dados da EMA de Santa Maria (A803, mesmos dados do item **a** do exercício anterior) ocorreram casos em que a temperatura máxima (mínima) diária foi acima (abaixo) dos recordes históricos registrados pela estação meteorológica convencional do INMET de Santa Maria (site 83936). Os recordes históricos de temperatura máxima e mínima estão disponíveis nos dados `recordes_temp` para cada mês do ano. Você deve obter os casos suspeitos na estrutura conforme abaixo.

```
# A tibble: 8 x 7
  date                 tmax  tmin   mes site 
  <dttm>              <dbl> <dbl> <dbl> <chr>
1 2009-10-30 00:00:00  35.8  20.4    10 83936
2 2009-10-31 00:00:00  36.8  21.8    10 83936
3 2013-12-26 00:00:00  38.3  21.2    12 83936
4 2014-02-05 00:00:00  38    23.8     2 83936
5 2014-02-06 00:00:00  38.3  24.4     2 83936
6 2014-02-07 00:00:00  39.5  23.2     2 83936
7 2014-02-09 00:00:00  38.3  22.9     2 83936
8 2014-10-29 00:00:00  36.8  22.4    10 83936
# ... with 2 more variables: tmin_abs <dbl>,
#   tmax_abs <dbl>
```


```{r}
# verificando a estrutura
str(recordes_temp)

# filtrando o data frame para o site 83936
recordes <- 
  recordes_temp %>%
  filter(site == 83936) %>%
  select(., month, site, tmin_abs, tmax_abs) %>%
  rename(., "mes" = month) 

head(recordes, n = 8)

```


```{r}
# com o resultado da questão a), combina-se o data frame "dias completos" com o 
# data frame "ema_sm_tair" para obter apenas os dias com dados não faltantes

emac <- inner_join(
  x = dias_completos, 
  y = ema_sm_tair,
  by = "dia"
)

```


```{r}
# trabalhando o novo quadro de dados
emac_sm <-
  emac %>%
  group_by(., dia) %>%
  select(., site, dia, tair) %>%
  summarise(.,
            site_ema = site[which.max(tair)],
            tmax = tair[which.max(tair)], # min(tair, na.rm = TRUE)
            tmin = tair[which.min(tair)],
            nobs = n(),
            .groups = 'drop') %>%
            mutate(., mes = month(as.POSIXlt(dia, format="%Y-%m-%d"))) %>%
  select(., site_ema, dia, everything()) %>%
  rename(., "date" = dia)

```


```{r}
# combinando as matrizes em relação aos meses
ema_compara <- inner_join(
  x = emac_sm, 
  y = recordes,
  by = "mes"
)

# filtrando os valores de tmax acima dos valores recordes
ema_recordes <-
  ema_compara %>%
  filter(., tmax > tmax_abs)

glimpse(ema_recordes)
```

> Seu arquivo não está conforme padrão solicitado (`lista4-adar-NomedoAluno.Rmd`). A penalização foi adicionada na questão 14 só para facilitar o cálculo de nota. Mas sua resolução deta questão está certa.


```{r jdt-correcao14, echo = FALSE, comment = "JDT>"}
p14 <- 0.5
(nq14 <- 1 - p14)
```


```{r jdt-nota-final, comment = "JDT>", echo=FALSE}
# requer conexão de internet
source("https://gist.githubusercontent.com/lhmet/3ddfc43bcf796c81ecfd9bb93f5f5dc2/raw/b489a6bb4d948472afa5068256b7869a7997e109/aux-funs-list-correction")
coleta_notas
# verificação de autoria
nota <- round((sum(coleta_notas)/length(coleta_notas) * 10), 1)
message("Nota: ", nota)

```
